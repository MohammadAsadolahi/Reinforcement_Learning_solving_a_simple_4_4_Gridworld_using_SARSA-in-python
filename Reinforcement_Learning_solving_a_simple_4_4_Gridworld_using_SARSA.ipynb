{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "class GridWorld:\n",
        "    def __init__(self):\n",
        "        # S O O O\n",
        "        # O O O *\n",
        "        # O * O O\n",
        "        # O * 0 T\n",
        "        self.qTable = None\n",
        "        self.actionSpace = ('U', 'D', 'L', 'R')\n",
        "        self.actions = {\n",
        "            (0, 0): ('D', 'R'),\n",
        "            (0, 1): ('L', 'D', 'R'),\n",
        "            (0, 2): ('L', 'D', 'R'),\n",
        "            (0, 3): ('L', 'D'),\n",
        "            (1, 0): ('U', 'D', 'R'),\n",
        "            (1, 1): ('U', 'L', 'D', 'R'),\n",
        "            (1, 2): ('U', 'L', 'D', 'R'),\n",
        "            (1, 3): ('U', 'L', 'D'),\n",
        "            (2, 0): ('U', 'D', 'R'),\n",
        "            (2, 1): ('U', 'L', 'D', 'R'),\n",
        "            (2, 2): ('U', 'L', 'D', 'R'),\n",
        "            (2, 3): ('U', 'L', 'D'),\n",
        "            (3, 0): ('U', 'R'),\n",
        "            (3, 1): ('U', 'L', 'R'),\n",
        "            (3, 2): ('U', 'L', 'R')\n",
        "        }\n",
        "        self.rewards = {(3, 3): 0.5, (1, 3): -0.5, (2, 1):-0.5, (3, 1):-0.5}\n",
        "        self.explored = 0\n",
        "        self.exploited = 0\n",
        "        self.initialQtable()\n",
        "\n",
        "    def initialQtable(self):\n",
        "      self.qTable = {}\n",
        "      for state in self.actions:\n",
        "          self.qTable[state]={}\n",
        "          for move in self.actions[state]:\n",
        "              self.qTable[state][move]=0\n",
        "      print(self.qTable)\n",
        "\n",
        "    def updateQtable(self, newQ,updateRate=0.05):\n",
        "        for state in self.qTable:\n",
        "            for action in self.qTable[state]:\n",
        "                self.qTable[state][action] = self.qTable[state][action]+(updateRate*(newQ[state][action]-self.qTable[state][action]))\n",
        "   \n",
        "    def getRandomPolicy(self):\n",
        "        policy = {}\n",
        "        for state in self.actions:\n",
        "            policy[state] = np.random.choice(self.actions[state])\n",
        "        return policy\n",
        "\n",
        "    def reset(self):\n",
        "        return (0, 0)\n",
        "        \n",
        "    def is_terminal(self, s):\n",
        "        return s not in self.actions\n",
        "\n",
        "    def getNewState(self,state,action):\n",
        "      i, j = zip(state)\n",
        "      row = int(i[0])\n",
        "      column = int(j[0])\n",
        "      if action == 'U':\n",
        "          row -= 1\n",
        "      elif action == 'D':\n",
        "          row += 1\n",
        "      elif action == 'L':\n",
        "          column -= 1\n",
        "      elif action == 'R':\n",
        "          column += 1\n",
        "      return row,column\n",
        "\n",
        "    def chooseAction(self, state, policy, exploreRate=0.01):\n",
        "        if exploreRate > np.random.rand():\n",
        "            self.explored += 1\n",
        "            return np.random.choice(self.actions[state])\n",
        "        self.exploited += 1\n",
        "        return policy[state]\n",
        "\n",
        "    def move(self, state, policy, exploreRate):\n",
        "        action = self.chooseAction(state, policy, exploreRate)\n",
        "        row,column=self.getNewState(state,action)\n",
        "        if (row, column) in self.rewards:\n",
        "            return action,(row, column),self.rewards[(row, column)]\n",
        "        return action,(row, column),-0.01\n",
        "        \n",
        "    def printPolicy(self, policy):\n",
        "        line = \"\"\n",
        "        counter = 0\n",
        "        for item in policy:\n",
        "            line += f\" | {policy[item]} | \"\n",
        "            counter += 1\n",
        "            if counter > 3:\n",
        "                print(line)\n",
        "                print(\"----------------------------\")\n",
        "                counter = 0\n",
        "                line = \"\"\n",
        "        print(line)\n",
        "        print(\"----------------------------\")"
      ],
      "metadata": {
        "id": "Hq-5-5RbNPiZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env= GridWorld()\n",
        "policy = env.getRandomPolicy()\n",
        "# policy = {(0, 0): 'R', (0, 1): 'R', (0, 2): 'D', (0, 3): 'L', (1, 0): 'U', (1, 1): 'R', (1, 2): 'D', (1, 3): 'D'\n",
        "#     ,(2, 0): 'D', (2, 1): 'R', (2, 2): 'R', (2, 3): 'D', (3, 0): 'R', (3, 1): 'R', (3, 2): 'R'}\n",
        "# env.printPolicy(policy)\n",
        "\n",
        "alpha=0.1\n",
        "for i in range(2000):\n",
        "    state = env.reset()\n",
        "    stepCounts=0\n",
        "    while (not env.is_terminal(state)) and (stepCounts<20):\n",
        "        action, nextState, reward = env.move(state, policy,0.01)\n",
        "        stepCounts += 1\n",
        "        targetQ=reward\n",
        "        if not env.is_terminal(nextState):\n",
        "          targetQ=reward+(0.9*env.qTable[nextState][env.chooseAction(nextState,policy)])\n",
        "        env.qTable[state][action]=env.qTable[state][action]+alpha*(targetQ-env.qTable[state][action])\n",
        "        state = nextState\n",
        "    for state in policy:\n",
        "      policy[state] = max(env.qTable[state], key=env.qTable[state].get)\n",
        "    if i%200==0:\n",
        "        print(f\"\\n\\n\\n step:{i}\")\n",
        "        env.printPolicy(policy)\n",
        "        print(\"\\n\")\n",
        "print(f\"exploited:{env.exploited}  explored:{env.explored}\")\n"
      ],
      "metadata": {
        "id": "VEg6wmxJzET8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a378d49e-6a53-4a13-db71-344352c85fa3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{(0, 0): {'D': 0, 'R': 0}, (0, 1): {'L': 0, 'D': 0, 'R': 0}, (0, 2): {'L': 0, 'D': 0, 'R': 0}, (0, 3): {'L': 0, 'D': 0}, (1, 0): {'U': 0, 'D': 0, 'R': 0}, (1, 1): {'U': 0, 'L': 0, 'D': 0, 'R': 0}, (1, 2): {'U': 0, 'L': 0, 'D': 0, 'R': 0}, (1, 3): {'U': 0, 'L': 0, 'D': 0}, (2, 0): {'U': 0, 'D': 0, 'R': 0}, (2, 1): {'U': 0, 'L': 0, 'D': 0, 'R': 0}, (2, 2): {'U': 0, 'L': 0, 'D': 0, 'R': 0}, (2, 3): {'U': 0, 'L': 0, 'D': 0}, (3, 0): {'U': 0, 'R': 0}, (3, 1): {'U': 0, 'L': 0, 'R': 0}, (3, 2): {'U': 0, 'L': 0, 'R': 0}}\n",
            "\n",
            "\n",
            "\n",
            " step:0\n",
            " | D |  | L |  | L |  | L | \n",
            "----------------------------\n",
            " | U |  | U |  | U |  | U | \n",
            "----------------------------\n",
            " | U |  | U |  | U |  | U | \n",
            "----------------------------\n",
            " | U |  | U |  | U | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " step:200\n",
            " | D |  | D |  | D |  | L | \n",
            "----------------------------\n",
            " | R |  | R |  | D |  | D | \n",
            "----------------------------\n",
            " | D |  | R |  | D |  | L | \n",
            "----------------------------\n",
            " | U |  | L |  | R | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " step:400\n",
            " | D |  | D |  | D |  | L | \n",
            "----------------------------\n",
            " | R |  | R |  | D |  | D | \n",
            "----------------------------\n",
            " | U |  | R |  | D |  | L | \n",
            "----------------------------\n",
            " | U |  | L |  | R | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " step:600\n",
            " | D |  | D |  | D |  | L | \n",
            "----------------------------\n",
            " | R |  | R |  | D |  | D | \n",
            "----------------------------\n",
            " | U |  | R |  | D |  | L | \n",
            "----------------------------\n",
            " | U |  | L |  | R | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " step:800\n",
            " | D |  | D |  | D |  | L | \n",
            "----------------------------\n",
            " | R |  | R |  | D |  | D | \n",
            "----------------------------\n",
            " | U |  | R |  | D |  | L | \n",
            "----------------------------\n",
            " | U |  | L |  | R | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " step:1000\n",
            " | D |  | D |  | D |  | L | \n",
            "----------------------------\n",
            " | R |  | R |  | D |  | D | \n",
            "----------------------------\n",
            " | U |  | R |  | D |  | L | \n",
            "----------------------------\n",
            " | U |  | L |  | R | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " step:1200\n",
            " | D |  | D |  | D |  | L | \n",
            "----------------------------\n",
            " | R |  | R |  | D |  | D | \n",
            "----------------------------\n",
            " | U |  | R |  | D |  | L | \n",
            "----------------------------\n",
            " | U |  | L |  | R | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " step:1400\n",
            " | D |  | D |  | D |  | L | \n",
            "----------------------------\n",
            " | R |  | R |  | D |  | D | \n",
            "----------------------------\n",
            " | U |  | R |  | D |  | L | \n",
            "----------------------------\n",
            " | U |  | L |  | R | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " step:1600\n",
            " | D |  | D |  | D |  | L | \n",
            "----------------------------\n",
            " | R |  | R |  | D |  | D | \n",
            "----------------------------\n",
            " | U |  | R |  | D |  | L | \n",
            "----------------------------\n",
            " | U |  | L |  | R | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " step:1800\n",
            " | D |  | D |  | D |  | L | \n",
            "----------------------------\n",
            " | R |  | R |  | D |  | D | \n",
            "----------------------------\n",
            " | U |  | R |  | D |  | L | \n",
            "----------------------------\n",
            " | U |  | L |  | R | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "exploited:23385  explored:224\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Reinforcement-Learning-solving-a-simple-4-4-Gridworld-using-SARSA",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}